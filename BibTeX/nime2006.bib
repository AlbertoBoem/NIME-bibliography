@inproceedings{Aylward2006,
author = {Aylward, Ryan and Paradiso, Joseph A.},
url = {http://www.nime.org/proceedings/2006/nime2006_134.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sensemble: A Wireless, Compact, Multi-User Sensor System for Interactive Dance},
year = {2006},
abstract = {We describe the design of a system of compact, wireless sensor modules meant to capture expressive motion whenworn at the wrists and ankles of a dancer. The sensors form ahigh-speed RF network geared toward real-time dataacquisition from multiple devices simultaneously, enabling asmall dance ensemble to become a collective interface formusic control. Each sensor node includes a 6-axis inertialmeasurement unit (IMU) comprised of three orthogonalgyroscopes and accelerometers in order to capture localdynamics, as well as a capacitive sensor to measure closerange node-to-node proximity. The nodes may also beaugmented with other digital or analog sensors. This paperdescribes application goals, presents the prototype hardwaredesign, introduces concepts for feature extraction andinterpretation, and discusses early test results.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Interactive dance, wearable sensor networks, inertial gesture tracking, collective motion analysis, multi-user interface },
pages = {134--139},
}
@inproceedings{Beilharz2006,
author = {Beilharz, Kirsty and Jakovich, Joanne and Ferguson, Sam},
url = {http://www.nime.org/proceedings/2006/nime2006_352.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Hyper-shaku (Border-crossing): Towards the Multi-modal Gesture-controlled Hyper-Instrument},
year = {2006},
abstract = {Hyper-shaku (Border-Crossing) is an interactive sensor environment that uses motion sensors to trigger immediate responses and generative processes augmenting the Japanese bamboo shakuhachi in both the auditory and visual domain. The latter differentiates this process from many hyper-instruments by building a performance of visual design as well as electronic music on top of the acoustic performance. It utilizes a combination of computer vision and wireless sensing technologies conflated from preceding works. This paper outlines the use of gesture in these preparatory sound and audio-visual performative, installation and sonification works, leading to a description of the Hyper-shaku environment integrating sonification and generative elements. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Gesture-controllers, sonification, hyper-instrument  },
pages = {352--357},
}
@inproceedings{Bennett2006,
author = {Bennett, Peter},
url = {http://www.nime.org/proceedings/2006/nime2006_081.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {PETECUBE: a Multimodal Feedback Interface},
year = {2006},
abstract = {The PETECUBE project consists of a series of musical interfaces designed to explore multi-modal feedback. This paper will briefly describe the definition of multimodal feedback, the aim of the project, the development of the first PETECUBE and proposed further work. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Multi-modal Feedback. Haptics. Musical Instrument.  },
pages = {81--84},
}
@inproceedings{Bevilacqua2006,
author = {Bevilacqua, Fr\'{e}d\'{e}ric and Rasamimanana, Nicolas and Fl\'{e}ty, Emmanuel and Lemouton, Serge and Baschet, Florence},
url = {http://www.nime.org/proceedings/2006/nime2006_402.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Augmented Violin Project: Research, Composition and Performance Report},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {402--406},
}
@inproceedings{Birchfield2006,
author = {Birchfield, David and Phillips, Kelly and Kidan\'{e}, Assegid and Lorig, David},
url = {http://www.nime.org/proceedings/2006/nime2006_043.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Interactive Public Sound Art: a case study},
year = {2006},
abstract = {Physically situated public art poses significant challenges for the design and realization of interactive, electronic sound works. Consideration of diverse audiences, environmental sensitivity, exhibition conditions, and logistics must guide the artwork. We describe our work in this area, using a recently installed public piece, Transition Soundings, as a case study that reveals a specialized interface and open-ended approach to interactive music making. This case study serves as a vehicle for examination of the real world challenges posed by public art and its outcomes. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Music, Sound, Interactivity, Arts, Public Art, Network Systems,  Sculpture, Installation Art, Embedded Electronics.  },
pages = {43--48},
}
@inproceedings{Bonardi2006,
author = {Bonardi, Alain and Truck, Isis and Akdag, Herman},
url = {http://www.nime.org/proceedings/2006/nime2006_326.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards a Virtual Assistant for Performers and Stage Directors},
year = {2006},
abstract = {In this article, we present the first step of our research work todesign a Virtual Assistant for Performers and Stage Directors,able to give a feedback from performances. We use amethodology to automatically construct fuzzy rules in a FuzzyRule-Based System that detects contextual emotions from anactor's performance during a show.We collect video data from a lot of performances of the sameshow from which it should be possible to visualize all theemotions and intents or more precisely "intent graphs". Toperform this, the collected data defining low-level descriptorsare aggregated and converted into high-level characterizations.Then, depending on the retrieved data and on their distributionon the axis, we partition the universes into classes. The last stepis the building of the fuzzy rules that are obtained from theclasses and that permit to give conclusions to label the detectedemotions.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Virtual Assistant, Intents, Emotion detector, Fuzzy Classes, Stage Director, Performance. },
pages = {326--329},
}
@inproceedings{Borchers2006,
author = {Borchers, Jan and Hadjakos, Aristotelis and M\"{u}hlh\"{a}user, Max},
url = {http://www.nime.org/proceedings/2006/nime2006_254.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {MICON A Music Stand for Interactive Conducting},
year = {2006},
abstract = {The MICON is an electronic music stand extending Maestro!, the latest in a series of interactive conducting exhibits that use real orchestral audio and video recordings. The MICON uses OpenGL-based rendering to display and animate score pages with a high degree of realism. It offers three different score display formats to match the user's level of expertise. A realtime animated visual cueing system helps users with their conducting. The MICON has been evaluated with music students. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Music stand, score display, exhibit, conducting.  },
pages = {254--259},
}
@inproceedings{Bottoni2006,
author = {Bottoni, Paolo and Faralli, Stefano and Labella, Anna and Pierro, Mario},
url = {http://www.nime.org/proceedings/2006/nime2006_322.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Mapping with Planning Agents in the Max/MSP Environment: the GO/Max Language},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {mapping, planning, agent, Max/MSP },
pages = {322--325},
}
@inproceedings{Bowers2006,
author = {Bowers, John and Villar, Nicolas},
url = {http://www.nime.org/proceedings/2006/nime2006_234.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Creating Ad Hoc Instruments with Pin\&Play\&Perform},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Ad hoc instruments, Pin&Play, physical interfaces, music performance, new interfaces for musical expression. },
pages = {234--239},
}
@inproceedings{Breinbjerg2006,
author = {Breinbjerg, Morten and Caprani, Ole and Lunding, Rasmus and Kramhoft, Line},
url = {http://www.nime.org/proceedings/2006/nime2006_334.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Acousmatic Composition Environment},
year = {2006},
abstract = {In this paper we describe the intentions, the design and functionality of an Acousmatic Composition Environment that allows children or musical novices to educate their auditory curiosity by recording, manipulating and mixing sounds of everyday life. The environment consists of three stands: A stand for sound recording with a soundproof box that ensure good recording facilities in a noisy environment; a stand for sound manipulation with five simple, tangible interfaces; a stand for sound mixing with a graphical computer interface presented on two touch screens. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Acousmatic listening, aesthetics, tangible interfaces.  },
pages = {334--337},
}
@inproceedings{BryanKinns2006,
author = {Bryan-Kinns, Nick and Healey, Patrick G.},
url = {http://www.nime.org/proceedings/2006/nime2006_114.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Decay in Collaborative Music Making},
year = {2006},
abstract = {This paper reports on ongoing studies of the design and use ofsupport for remote group music making. In this paper weoutline the initial findings of a recent study focusing on thefunction of decay of contributions in collaborative musicmaking. Findings indicate that persistent contributions lendthemselves to individual musical composition and learningnovel interfaces, whilst contributions that quickly decayengender a more focused musical interaction in experiencedparticipants.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {creativity,design,group interaction,music improvisation},
pages = {114--117},
}
@inproceedings{Burns2006,
author = {Burns, Anne-Marie and Wanderley, Marcelo M.},
url = {http://www.nime.org/proceedings/2006/nime2006_196.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Visual Methods for the Retrieval of Guitarist Fingering},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {finger-tracking,gesture,guitar fingering,hough transform},
pages = {196--199},
}
@inproceedings{Burtner2006,
author = {Burtner, Matthew},
url = {http://www.nime.org/proceedings/2006/nime2006_129.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Perturbation Techniques for Multi-Performer or Multi- Agent Interactive Musical Interfaces},
year = {2006},
abstract = {This paper explores the use of perturbation in designing multiperformer or multi-agent interactive musical interfaces. A problem with the multi-performer approach is how to cohesively organize the independent data inputs into useable control information for synthesis engines. Perturbation has proven useful for navigating multi-agent NIMEs. The ,
,
author's Windtree is discussed as an example multi-performer instrument in which perturbation is used for multichannel ecological modeling. The Windtree uses a physical system turbulence model controlled in real time by four performers. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {interface,mapping,movement,multi-agent,multi-performer,music composition,perturbation},
pages = {129--133},
}
@inproceedings{Crevoisier2006,
author = {Crevoisier, Alain and Bornand, C\'{e}dric and Guichard, Arnaud and Matsumura, Seiichiro and Arakawa, Chuichi},
url = {http://www.nime.org/proceedings/2006/nime2006_212.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Sound Rose: Creating Music and Images with a Touch Table},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {212--215},
}
@inproceedings{dAlessandro2006,
author = {d'Alessandro, Nicolas and d'Alessandro, Christophe and {Le Beux}, Sylvain and Doval, Boris},
url = {http://www.nime.org/proceedings/2006/nime2006_266.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Real-time CALM Synthesizer: New Approaches in Hands-Controlled Voice Synthesis},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Singing synthesis, voice source, voice quality, spectral model, formant synthesis, instrument, gestural control. },
pages = {266--271},
}
@inproceedings{Davidson2006,
author = {Davidson, Philip L. and Han, Jefferson Y.},
url = {http://www.nime.org/proceedings/2006/nime2006_216.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Synthesis and Control on Large Scale Multi-Touch Sensing Displays},
year = {2006},
abstract = {In this paper, we describe our experience in musical interface design for a large scale, high-resolution, multi-touch display surface. We provide an overview of historical and presentday context in multi-touch audio interaction, and describe our approach to analysis of tracked multi-finger, multi-hand data for controlling live audio synthesis.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {multi-touch, touch, tactile, bi-manual, multi-user, synthesis,  dynamic patching },
pages = {216--219},
}
@inproceedings{DeJong2006,
author = {de Jong, Staas},
url = {http://www.nime.org/proceedings/2006/nime2006_079.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Tactile Closed-Loop Device for Musical Interaction},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {79--80},
}
@inproceedings{DeLaubier2006,
author = {de Laubier, Serge and Goudard, Vincent},
url = {http://www.nime.org/proceedings/2006/nime2006_288.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Meta-Instrument 3: a Look over 17 Years of Practice},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {1,audio-graphic portable instrument,ethernet,from 1983 to 1988,genesis of the project,on,puce muse studios,r\'{e}pertoire,we worked at the,wifi},
pages = {288--291},
}
@inproceedings{Dimitrov2006,
author = {Dimitrov, Smilen and Serafin, Stefania},
url = {http://www.nime.org/proceedings/2006/nime2006_184.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Simple Practical Approach to a Wireless Data Acquisition Board},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {184--187},
}
@inproceedings{Dobrian2006,
author = {Dobrian, Christopher and Koppelman, Daniel},
url = {http://www.nime.org/proceedings/2006/nime2006_277.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The E in NIME: Musical Expression with New Computer Interfaces},
year = {2006},
abstract = {Is there a distinction between New Interfaces for MusicalExpression and New Interfaces for Controlling Sound? Thisarticle begins with a brief overview of expression in musicalperformance, and examines some of the characteristics ofeffective "expressive" computer music instruments. Itbecomes apparent that sophisticated musical expressionrequires not only a good control interface but also virtuosicmastery of the instrument it controls. By studying effectiveacoustic instruments, choosing intuitive but complexgesture-sound mappings that take advantage of establishedinstrumental skills, designing intelligent characterizationsof performance gestures, and promoting long-term dedicatedpractice on a new interface, computer music instrumentdesigners can enhance the expressive quality of computermusic performance.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Expression, instrument design, performance, virtuosity. },
pages = {277--282},
}
@inproceedings{Farwell2006,
author = {Farwell, Neal},
url = {http://www.nime.org/proceedings/2006/nime2006_358.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Adapting the Trombone: a Suite of Electro-acoustic Interventions for the Piece},
year = {2006},
abstract = {Three electro-acoustic systems were devised for a newtrombone work, Rouse. This paper presents the technicalsystems and outlines their musical context and motivation. TheuSlide measures trombone slide-extension by a minimalhardware ultrasonic technique. An easy calibration proceduremaps linear extension to the slide "positions" of the player. TheeMouth is a driver that replaces the mouthpiece, with softwareemulation of trombone tone and algorithmic musical lines,allowing the trombone to appear to play itself. The eMute isbuilt around a loudspeaker unit, driven so that it affects stronglythe player's embouchure, allowing fine control of complex beatpatterns. eMouth and eMute, under control of the uSlide, set upimprovisatory worlds that are part of the composed architectureof Rouse.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {composition,electro-acoustic adaptation,emulation,illusion,improvisation,mapping,mute,trombone,ultrasonic},
pages = {358--363},
}
@inproceedings{Favilla2006,
author = {Favilla, Stuart and Cannon, Joanne},
url = {http://www.nime.org/proceedings/2006/nime2006_370.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Children of Grainger: Leather Instruments for Free Music},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {370--375},
}
@inproceedings{Ferguson2006,
author = {Ferguson, Sam},
url = {http://www.nime.org/proceedings/2006/nime2006_384.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Learning Musical Instrument Skills Through Interactive Sonification},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {interactive sonification,music,sonification,sound visualization},
pages = {384--389},
}
@inproceedings{Freed2006,
author = {Freed, Adrian and Avizienis, Rimas and Wright, Matthew},
url = {http://www.nime.org/proceedings/2006/nime2006_097.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Beyond 0-5V: Expanding Sensor Integration Architectures},
year = {2006},
abstract = {A new sensor integration system and its first incarnation i sdescribed. As well as supporting existing analog sensorarrays a new architecture allows for easy integration of thenew generation of low-cost digital sensors used in computermusic performance instruments and installation art.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Gesture, sensor, MEMS, FPGA, network, OSC, configurability },
pages = {97--100},
}
@inproceedings{Freed2006a,
author = {Freed, Adrian and Wessel, David and Zbyszynski, Michael and Uitti, Frances M.},
url = {http://www.nime.org/proceedings/2006/nime2006_409.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Augmenting the Cello},
year = {2006},
abstract = {Software and hardware enhancements to an electric 6-stringcello are described with a focus on a new mechanical tuningdevice, a novel rotary sensor for bow interaction and controlstrategies to leverage a suite of polyphonic soundprocessing effects.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Cello, chordophone, FSR, Rotary Absolute Position Encoder, Double Bowing, triple stops, double stops, convolution. },
pages = {409--413},
}
@inproceedings{Gaye2006,
author = {Gaye, Lalya and Holmquist, Lars E. and Behrendt, Frauke and Tanaka, Atau},
url = {http://www.nime.org/proceedings/2006/nime2006_022.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Mobile Music Technology: Report on an Emerging Community},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {22--25},
}
@inproceedings{Geiger2006,
author = {Geiger, G\"{u}nter},
url = {http://www.nime.org/proceedings/2006/nime2006_061.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Using the Touch Screen as a Controller for Portable Computer Music Instruments},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {touch screen, PDA, Pure Data, controller, mobile musical instrument, human computer interaction },
pages = {61--64},
}
@inproceedings{Goto2006,
author = {Goto, Suguru},
url = {http://www.nime.org/proceedings/2006/nime2006_292.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Case Study of An Application of The System, “BodySuit” and “RoboticMusic”: Its Introduction and Aesthetics},
year = {2006},
abstract = {This paper is intended to introduce the system, whichcombines "BodySuit" and "RoboticMusic," as well as itspossibilities and its uses in an artistic application."BodySuit" refers to a gesture controller in a Data Suit type."RoboticMusic" refers to percussion robots, which are appliedto a humanoid robot type. In this paper, I will discuss theiraesthetics and the concept, as well as the idea of the "ExtendedBody".},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Robot, Gesture Controller, Humanoid Robot, Artificial Intelligence, Interaction },
pages = {292--295},
}
@inproceedings{Gurevich2006,
author = {Gurevich, Michael},
url = {http://www.nime.org/proceedings/2006/nime2006_118.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {JamSpace: Designing A Collaborative Networked Music Space for Novices},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Collaborative interface, remote jamming, network music, interaction design, novice, media space INTRODUCTION Most would agree that music is an inherently social ac- tivity [30], but since the },
pages = {118--123},
}
@inproceedings{Hamel2006,
author = {Hamel, Keith},
url = {http://www.nime.org/proceedings/2006/nime2006_380.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Integrated Interactive Music Performance Environment},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {380--383},
}
@inproceedings{Hamilton2006,
author = {Hamilton, Robert},
url = {http://www.nime.org/proceedings/2006/nime2006_338.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Bioinformatic Feedback: Performer Bio-data as a Driver for Real-time Composition},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Bioinformatics, composition, real-time score generation. },
pages = {338--341},
}
@inproceedings{Hansen2006,
author = {Hansen, Kjetil F. and Bresin, Roberto},
url = {http://www.nime.org/proceedings/2006/nime2006_188.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Mapping Strategies in DJ Scratching},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {controllers,dj,instrument mapping,scratching,virtual},
pages = {188--191},
}
@inproceedings{Hindman2006,
author = {Hindman, David},
url = {http://www.nime.org/proceedings/2006/nime2006_296.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Modal Kombat: Competition and Choreography in Synesthetic Musical Performance},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {296--299},
}
@inproceedings{Holm2006,
author = {Holm, Jukka and Arrasvuori, Juha and Havukainen, Kai},
url = {http://www.nime.org/proceedings/2006/nime2006_065.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Using MIDI to Modify Video Game Content},
year = {2006},
abstract = {This paper discusses the concept of using background music to control video game parameters and thus actions on the screen. Each song selected by the player makes the game look different and behave variedly. The concept is explored by modifying an existing video game and playtesting it with different kinds of MIDI music. Several examples of mapping MIDI parameters to game events are presented. As mobile phones' MIDI players do not usually have a dedicated callback API, a real-time MIDI analysis software for Symbian OS was implemented. Future developments including real-time group performance as a way to control game content are also considered. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Games, MIDI, music, rhythm games, background music  reactive games, musically controlled games, MIDI-controlled  games, Virtual Sequencer.  },
pages = {65--70},
}
@inproceedings{Hsu2006,
author = {Hsu, William},
url = {http://www.nime.org/proceedings/2006/nime2006_376.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Managing Gesture and Timbre for Analysis and Instrument Control in an Interactive Environment},
year = {2006},
abstract = {This paper describes recent enhancements in an interactive system designed to improvise with saxophonist John Butcher [1]. In addition to musical parameters such as pitch and loudness, our system is able to analyze timbral characteristics of the saxophone tone in real-time, and use timbral information to guide the generation of response material. We capture each saxophone gesture on the fly, extract a set of gestural and timbral contours, and store them in a repository. Improvising agents can consult the repository when generating responses. The gestural or timbral progression of a saxophone phrase can be remapped or transformed; this enables a variety of response material that also references audible contours of the original saxophone gestures. A single simple framework is used to manage gestural and timbral information extracted from analysis, and for expressive control of virtual instruments in a free improvisation context. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Interactive music systems, timbre analysis, instrument control.  },
pages = {376--379},
}
@inproceedings{Jacquemin2006,
author = {Jacquemin, Christian and de Laubier, Serge},
url = {http://www.nime.org/proceedings/2006/nime2006_156.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Transmodal Feedback as a New Perspective for Audio-visual Effects},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {audio-visual composition,feedback,transmodality},
pages = {156--161},
}
@inproceedings{Francois2006,
author = {Francois, Alexander R. and Chew, Elaine},
url = {http://www.nime.org/proceedings/2006/nime2006_150.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {An Architectural Framework for Interactive Music Systems},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Software Architecture, Interactive Systems, Music soft- ware },
pages = {150--155},
}
@inproceedings{Jensenius2006a,
author = {Jensenius, Alexander R. and Kvifte, Tellef and God\o y, Rolf I.},
url = {http://www.nime.org/proceedings/2006/nime2006_176.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards a Gesture Description Interchange Format},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Gesture description, gesture analysis, standards },
pages = {176--179},
}
@inproceedings{Johnson2006,
author = {Johnson, Colin G. and Gounaropoulos, Alex},
url = {http://www.nime.org/proceedings/2006/nime2006_101.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Timbre Interfaces using Adjectives and Adverbs},
year = {2006},
abstract = {How can we provide interfaces to synthesis algorithms thatwill allow us to manipulate timbre directly, using the sametimbre-words that are used by human musicians to communicate about timbre? This paper describes ongoingwork that uses machine learning methods (principally genetic algorithms and neural networks) to learn (1) to recognise timbral characteristics of sound and (2) to adjust timbral characteristics of existing synthesized sounds.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {timbre; natural language; neural networks },
pages = {101--102},
}
@inproceedings{Jorda2006,
author = {Jord\`{a}, Sergi and Alonso, Marcos},
url = {http://www.nime.org/proceedings/2006/nime2006_208.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Mary Had a Little scoreTable* or the reacTable* Goes Melodic},
year = {2006},
abstract = {This paper introduces the scoreTable*, a tangible interactive music score editor which started as a simple application for demoing "traditional" approaches to music creation, using the reacTable* technology, and which has evolved into an independent research project on its own. After a brief discussion on the role of pitch in music, we present a brief overview of related tangible music editors, and discuss several paradigms in computer music creation, contrasting synchronous with asynchronous approaches. The final part of the paper describes the current state of the scoreTable* as well as its future lines of research.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Musical instrument, Collaborative Music, Computer Supported  Collaborative Work, Tangible User Interface, Music Theory. },
pages = {208--211},
}
@inproceedings{Kartadinata2006,
author = {Kartadinata, Sukandar},
url = {http://www.nime.org/proceedings/2006/nime2006_093.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Gluion Advantages of an FPGA-based Sensor Interface},
year = {2006},
abstract = {The gluion is a sensor interface that was designed to overcomesome of the limitations of more traditional designs based onmicrocontrollers, which only provide a small, fixed number ofdigital modules such as counters and serial interfaces. These areoften required to handle sensors where the physical parametercannot easily be converted into a voltage. Other sensors arepacked into modules that include converters and communicatevia SPI or I2C. Finallly, many designs require outputcapabilities beyond simple on/off.The gluion approaches these challenges thru its FPGA-baseddesign which allows for a large number of digital I/O modules.It also provides superior flexibility regarding theirconfiguration, resolution, and functionality. In addition, theFPGA enables a software implementation of the host link - inthe case of the gluion the OSC protocol as well as theunderlying Ethernet layers.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {actuators,digital sensors,fpga,osc,sensor interfaces},
pages = {93--96},
}
@inproceedings{Kessous2006,
author = {Kessous, Lo\"{\i}c and Castet, Julien and Arfib, Daniel},
url = {http://www.nime.org/proceedings/2006/nime2006_192.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {'GXtar', an Interface Using Guitar Techniques},
year = {2006},
abstract = {In this paper we describe a new guitar-like musical controller. The 'GXtar' is an instrument which takes as a starting point a guitar but his role is to bring different and new musical possibilities while preserving the spirit and techniques of guitar. Therefore, it was conceived and carried out starting from the body of an electric guitar. The fingerboard of this guitar was equipped with two lines of sensors: linear position sensors, and tactile pressure sensors. These two lines of sensors are used as two virtual strings. Their two ends are the bridge and the nut of the guitar. The design of the instrument is made in a way that the position of a finger, on one of these virtual strings, corresponds to the note, which would have been played on a real and vibrating string. On the soundboard of the guitar, a controller, with 3 degrees of freedom, allows to drive other synthesis parameters. We then describe how this interface is integrated in a musical audio system and serves as a musical instrument. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Guitar, alternate controller, sensors, synthesizer, multidimensional  control.  },
pages = {192--195},
}
@inproceedings{Kimura2006,
author = {Kimura, Mari and Risset, Jean-Claude},
url = {http://www.nime.org/proceedings/2006/nime2006_407.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Auditory Illusion and Violin: Demonstration of a Work by Jean-Claude Risset Written for Mari Kimura},
year = {2006},
abstract = {This is a description of a demonstration, regarding theuse of auditory illusions and psycho-acoustic phenomenonused in the interactive work of Jean-Claude Risset, writtenfor violinist Mari Kimura.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Violin, psycho-acoustic phenomena, auditory illusions, sig- nal processing, subharmonics, Risset, Kimura. },
pages = {407--408},
}
@inproceedings{Kiser2006,
author = {Kiser, Spencer},
url = {http://www.nime.org/proceedings/2006/nime2006_075.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {spinCycle: a Color-Tracking Turntable Sequencer},
year = {2006},
abstract = {This report presents an interface for musical performance called the spinCycle. spinCycle enables performers to make visual patterns with brightly colored objects on a spinning turntable platter that get translated into musical arrangements in realtime. I will briefly describe the hardware implementation and the sound generation logic used, as well as provide a historical background for the project.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Color-tracking, turntable, visualization, interactivity, synesthesia },
pages = {75--76},
}
@inproceedings{Knapp2006,
author = {Knapp, Benjamin and Cook, Perry R.},
url = {http://www.nime.org/proceedings/2006/nime2006_124.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Creating a Network of Integral Music Controllers},
year = {2006},
abstract = {In this paper, we describe the networking of multiple Integral Music Controllers (IMCs) to enable an entirely new method for creating music by tapping into the composite gestures and emotions of not just one, but many performers. The concept and operation of an IMC is reviewed as well as its use in a network of IMC controllers. We then introduce a new technique of Integral Music Control by assessing the composite gesture(s) and emotion(s) of a group of performers through the use of a wireless mesh network. The Telemuse, an IMC designed precisely for this kind of performance, is described and its use in a new musical performance project under development by the ,
,
authors is discussed. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Community-Institutional Relations,Health Services Accessibility,Medically Uninsured,Organizational Case Studies,Primary Health Care,Public-Private Sector Partnerships,San Francisco},
pages = {124--128},
}
@inproceedings{Kobayashi2006,
author = {Kobayashi, Shigeru and Endo, Takanori and Harada, Katsuhiko and Oishi, Shosei},
url = {http://www.nime.org/proceedings/2006/nime2006_346.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {GAINER: A Reconfigurable I/O Module and Software Libraries for Education},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {learning,rapid prototyping,reconfigurable,sensor interface},
pages = {346--351},
}
@inproceedings{Kobori2006,
author = {Kobori, Daisuke and Kagawa, Kojiro and Iida, Makoto and Arakawa, Chuichi},
url = {http://www.nime.org/proceedings/2006/nime2006_110.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {LINE: Interactive Sound and Light Installation},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {110--113},
}
@inproceedings{Koehly2006,
author = {Koehly, Rodolphe and Curtil, Denis and Wanderley, Marcelo M.},
url = {http://www.nime.org/proceedings/2006/nime2006_230.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Paper FSRs and Latex/Fabric Traction Sensors: Methods for the Development of Home-Made Touch Sensors},
year = {2006},
abstract = {This paper presents the development of novel "home-made" touch sensors using conductive pigments and various substrate materials. We show that it is possible to build one's own position, pressure and bend sensors with various electrical characteristics, sizes and shapes, and this for a very competitive price. We give examples and provide results from experimental tests of such developments. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Touch sensors, piezoresistive technology, conductive pigments,  sensitive materials, interface design  },
pages = {230--233},
}
@inproceedings{Kvifte2006,
author = {Kvifte, Tellef and Jensenius, Alexander R.},
url = {http://www.nime.org/proceedings/2006/nime2006_220.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards a Coherent Terminology and Model of Instrument Description and Design},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Musical instrument design, mapping, gestures, organology. },
pages = {220--225},
}
@inproceedings{Lebel2006,
author = {Lebel, Denis and Malloch, Joseph},
url = {http://www.nime.org/proceedings/2006/nime2006_085.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The G-Spring Controller},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Digital musical instrument, kinesthetic feedback },
pages = {85--88},
}
@inproceedings{Lee2006,
author = {Lee, Eric and Gr\"{u}ll, Ingo and Keil, Henning and Borchers, Jan},
url = {http://www.nime.org/proceedings/2006/nime2006_260.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {conga: A Framework for Adaptive Conducting Gesture Analysis},
year = {2006},
abstract = {Designing a conducting gesture analysis system for public spacesposes unique challenges. We present conga, a software framework that enables automatic recognition and interpretation ofconducting gestures. conga is able to recognize multiple types ofgestures with varying levels of difficulty for the user to perform,from a standard four-beat pattern, to simplified up-down conducting movements, to no pattern at all. conga provides an extendablelibrary of feature detectors linked together into a directed acyclicgraph; these graphs represent the various conducting patterns asgesture profiles. At run-time, conga searches for the best profileto match a user's gestures in real-time, and uses a beat prediction algorithm to provide results at the sub-beat level, in additionto output values such as tempo, gesture size, and the gesture'sgeometric center. Unlike some previous approaches, conga doesnot need to be trained with sample data before use. Our preliminary user tests show that conga has a beat recognition rate ofover 90%. conga is deployed as the gesture recognition systemfor Maestro!, an interactive conducting exhibit that opened in theBetty Brinn Children's Museum in Milwaukee, USA in March2006.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {gesture recognition, conducting, software gesture frameworks },
pages = {260--265},
}
@inproceedings{Lee2006a,
author = {Lee, Jason},
url = {http://www.nime.org/proceedings/2006/nime2006_077.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Chopping Board: Real-time Sample Editor},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {77--78},
}
@inproceedings{Lehrman2006,
author = {Lehrman, Paul D. and Singer, Eric},
url = {http://www.nime.org/proceedings/2006/nime2006_300.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A "Ballet M\'{e}canique" for the 21st Century: Performing George Antheil's Dadaist Masterpiece with Robots},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Robotics, computer control, MIDI, player pianos, mechanical music, percussion, sound effects, Dadaism. },
pages = {300--303},
}
@inproceedings{Lemouton2006,
author = {Lemouton, Serge and Stroppa, Marco and Sluchin, Benny},
url = {http://www.nime.org/proceedings/2006/nime2006_304.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Using the Augmented Trombone in "I will not kiss your f.ing flag"},
year = {2006},
abstract = {This paper deals with the first musical usage of anexperimental system dedicated to the optical detection ofthe position of a trombone's slide.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {1,augmented instrument,chamber electronics,computer,interaction,musical motivation,performer,trombone},
pages = {304--307},
}
@inproceedings{Leroy2006,
author = {Leroy, Nicolas and Fl\'{e}ty, Emmanuel and Bevilacqua, Fr\'{e}d\'{e}ric},
url = {http://www.nime.org/proceedings/2006/nime2006_204.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Reflective Optical Pickup For Violin},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {204--207},
}
@inproceedings{Lippit2006,
author = {Lippit, Takuro M.},
url = {http://www.nime.org/proceedings/2006/nime2006_071.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Turntable Music in the Digital Era: Designing Alternative Tools for New Turntable Expression},
year = {2006},
abstract = {Turntable musicians have yet to explore new expressions with digital technology. New higher-level development tools open possibilities for these artists to build their own instruments that can achieve artistic goals commercial products cannot. This paper will present a rough overview on the practice and recent development of turntable music, followed by descriptions of two projects by the ,
,
author. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Turntable music, DJ, turntablist, improvisation, Max/MSP, PIC  Microcontroller, Physical Computing  },
pages = {71--74},
}
@inproceedings{Lock2006,
author = {Lock, Damien and Schiemer, Greg},
url = {http://www.nime.org/proceedings/2006/nime2006_089.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Orbophone: a New Interface for Radiating Sound and Image},
year = {2006},
abstract = {The Orbophone is a new interface that radiates rather thanprojects sound and image. It provides a cohesive platformfor audio and visual presentation in situations where bothmedia are transmitted from the same location andlocalization in both media is perceptually correlated. Thispaper discusses the advantages of radiation overconventional sound and image projection for certain kindsof interactive public multimedia exhibits and describes theartistic motivation for its development against a historicalbackdrop of sound systems used in public spaces. Oneexhibit using the Orbophone is described in detail togetherwith description and critique of the prototype, discussingaspects of its design and construction. The paper concludeswith an outline of the Orbophone version 2.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Immersive Sound; Multi-channel Sound; Loud-speaker Array; Multimedia; Streaming Media; Real-Time Media Performance; Sound Installation. },
pages = {89--92},
}
@inproceedings{Magnusson2006,
author = {Magnusson, Thor},
url = {http://www.nime.org/proceedings/2006/nime2006_162.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Screen-Based Musical Interfaces as Semiotic Machines},
year = {2006},
abstract = {The ixi software project started in 2000 with the intention to explore new interactive patterns and virtual interfaces in computer music software. The aim of this paper is not to describe these programs, as they have been described elsewhere [14][15], but rather explicate the theoretical background that underlies the design of these screen-based instruments. After an analysis of the similarities and differences in the design of acoustic and screen-based instruments, the paper describes how the creation of an interface is essentially the creation of a semiotic system that affects and influences the musician and the composer. Finally the terminology of this semiotics is explained as an interaction model. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Interfaces, interaction design, HCI, semiotics, actors, OSC,  mapping, interaction models, creative tools.  },
pages = {162--167},
}
@inproceedings{MakiPatola2006,
author = {Maki-Patola, Teemu and H\"{a}m\"{a}l\"{a}inen, Perttu and Kanerva, Aki},
url = {http://www.nime.org/proceedings/2006/nime2006_364.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Augmented Djembe Drum - Sculpting Rhythms},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {1,2,2 9,3897,39,425,43,7,8,9},
pages = {364--369},
}
@inproceedings{Marshall2006,
author = {Marshall, Mark T. and Wanderley, Marcelo M.},
url = {http://www.nime.org/proceedings/2006/nime2006_226.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Vibrotactile Feedback in Digital Musical Instruments},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {digital musical instruments,tactile feedback,vibro-tactile},
pages = {226--229},
}
@inproceedings{Naef2006,
author = {Naef, Martin and Collicott, Daniel},
url = {http://www.nime.org/proceedings/2006/nime2006_057.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A VR Interface for Collaborative 3D Audio Performance},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {57--60},
}
@inproceedings{Nagashima2006,
author = {Nagashima, Yoichi},
url = {http://www.nime.org/proceedings/2006/nime2006_330.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Students' Projects of Interactive Media-installations in SUAC},
year = {2006},
abstract = {This is a studio report of researches and projects in SUAC(Shizuoka University of Art and Culture). SUAC was foundedin April 2000, and organized NIME04 as you know. SUAChas "Faculty of Design" and "Department of Art and Science"and all students study interactive systems and media arts.SUAC has organized Media Art Festival (MAF) from 2001 to2005. Domestic/overseas artists participated in SUAC MAF,and SUAC students' projects also joined and exhibited theirworks in MAF. I will introduce the production cases withinteractive media-installations by SUAC students' projectsfrom the aspect "experiences with novel interfaces ineducation and entertainment" and "reports on students projectsin the framework of NIME related courses".},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Interactive Installation, Sensors, Media Arts, Studio Reports  },
pages = {330--333},
}
@inproceedings{Nishibori2006,
author = {Nishibori, Yu and Iwai, Toshio},
url = {http://www.nime.org/proceedings/2006/nime2006_172.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {TENORI-ON},
year = {2006},
abstract = {Development of a musical interface which allows people to play music intuitively and create music visibly. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {172--175},
}
@inproceedings{Nixdorf2006,
author = {Nixdorf, Joshua J. and Gerhard, David},
url = {http://www.nime.org/proceedings/2006/nime2006_318.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Real-time Sound Source Spatialization as Used in Challenging Bodies: Implementation and Performance},
year = {2006},
abstract = {In this paper we will report on the use of real-time soundspatialization in Challenging Bodies, a trans-disciplinaryperformance project at the University of Regina. Usingwell-understood spatialization techniques mapped to a custom interface, a computer system was built that allowedlive spatial control of ten sound signals from on-stage performers. This spatial control added a unique dynamic element to an already ultramodern performance. The systemis described in detail, including the main advantages overexisting spatialization systems: simplicity, usability, customization and scalability},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {gem,live systems,pd,performance sys-,real-time systems,sound architecture,sound localization,sound spatialization,surround sound,tems},
pages = {318--321},
}
@inproceedings{Pak2006,
author = {Pak, Jonathan},
url = {http://www.nime.org/proceedings/2006/nime2006_342.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Light Matrix: An Interface for Musical Expression and Performance},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {342--345},
}
@inproceedings{Poepel2006,
author = {Poepel, Cornelius and Overholt, Dan},
url = {http://www.nime.org/proceedings/2006/nime2006_390.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Recent Developments in Violin-related Digital Musical Instruments: Where Are We and Where Are We Going?},
year = {2006},
abstract = {In this paper, some of the more recent developments in musical instruments related to the violin family are described, and analyzed according to several criteria adapted from other publications. While it is impossible to cover all such developments, we have tried to sample a variety of instruments from the last decade or so, with a greater focus on those published in the computer music literature. Experiences in the field of string players focusing on such developments are presented. Conclusions are drawn in which further research into violin-related digital instruments for string players may benefit from the presented criteria as well as the experiences. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Violin, viola, cello, bass, digital, electronic, synthesis, controller.  },
pages = {390--395},
}
@inproceedings{Pritchard2006,
author = {Pritchard, Bob and Fels, Sidney S.},
url = {http://www.nime.org/proceedings/2006/nime2006_272.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {GRASSP: Gesturally-Realized Audio, Speech and Song Performance},
year = {2006},
abstract = {We describe the implementation of an environment for Gesturally-Realized Audio, Speech and Song Performance (GRASSP), which includes a glove-based interface, a mapping/training interface, and a collection of Max/MSP/Jitter bpatchers that allow the user to improvise speech, song, sound synthesis, sound processing, sound localization, and video processing. The mapping/training interface provides a framework for performers to specify by example the mapping between gesture and sound or video controls. We demonstrate the effectiveness of the GRASSP environment for gestural control of musical expression by creating a gesture-to-voice system that is currently being used by performers. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Speech synthesis, parallel formant speech synthesizer, gesture  control, Max/MSP, Jitter, Cyberglove, Polhemus, sound  diffusion, UBC Toolbox, Glove-Talk,  },
pages = {272--276},
}
@inproceedings{Ramakrishnan2006,
author = {Ramakrishnan, Chandrasekhar and Go\ss man, Joachim and Br\"{u}mmer, Ludger},
url = {http://www.nime.org/proceedings/2006/nime2006_140.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The ZKM Klangdom},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Sound Spatialization, Ambisonics, Vector Based Additive Panning (VBAP), Wave Field Synthesis, Acousmatic Music },
pages = {140--143},
}
@inproceedings{Rebelo2006,
author = {Rebelo, Pedro and Renaud, Alain B.},
url = {http://www.nime.org/proceedings/2006/nime2006_053.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {The Frequencyliator – Distributing Structures for Networked Laptop Improvisation},
year = {2006},
abstract = {The culture of laptop improvisation has grown tremendously in recent years. The development of personalized software instruments presents interesting issues in the context of improvised group performances. This paper examines an approach that is aimed at increasing the modes of interactivity between laptop performers and at the same time suggests ways in which audiences can better discern and identify the sonic characteristics of each laptop performer. We refer to software implementation that was developed for the BLISS networked laptop ensemble with view to designing a shared format for the exchange of messages within local and internet based networks. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Networked audio technologies, laptop ensemble, centralized  audio server, improvisation  },
pages = {53--56},
}
@inproceedings{Remus2006,
author = {R\'{e}mus, Jacques},
url = {http://www.nime.org/proceedings/2006/nime2006_250.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Non Haptic Control of Music by Video Analysis of Hand Movements: 14 Years of Experience with the «Cam\'{e}ra Musicale»},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {camera musicale,interface,jacques r\'{e}mus,machines,musical camera,musical hand,non haptic instrument,s mappings,sculptures and mechanical musical,sound},
pages = {250--253},
}
@inproceedings{Richards2006,
author = {Richards, John},
url = {http://www.nime.org/proceedings/2006/nime2006_283.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {32kg: Performance Systems for a Post-Digital Age},
year = {2006},
abstract = {Why is a seemingly mundane issue such as airline baggageallowance of great significance in regards to the performancepractice of electronic music? This paper discusses how aperformance practice has evolved that seeks to question thebinary and corporate digital world. New 'instruments' andapproaches have emerged that explore 'dirty electronics' and'punktronics': DIY electronic instruments made from junk.These instruments are not instruments in the traditionalsense, defined by physical dimensions or by a set number ofparameters, but modular systems, constantly evolving, nevercomplete, infinitely variable and designed to be portable. Acombination of lo- and hi-fi, analogue and digital,synchronous and asynchronous devices offer new modes ofexpression. The development of these new interfaces formusical expression run side-by-side with an emerging postdigital aesthetic.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {bastardisation,dirty electronics,diy,ebay,live,modular,performance,portability,post-digital,punktronics},
pages = {283--287},
}
@inproceedings{Rohs2006,
author = {Rohs, Michael and Essl, Georg and Roth, Martin},
url = {http://www.nime.org/proceedings/2006/nime2006_031.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {CaMus: Live Music Performance using Camera Phones and Visual Grid Tracking},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {31--36},
}
@inproceedings{Schiemer2006,
author = {Schiemer, Greg and Havryliv, Mark},
url = {http://www.nime.org/proceedings/2006/nime2006_037.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Pocket Gamelan: Tuneable Trajectories for Flying Sources in Mandala 3 and Mandala 4},
year = {2006},
abstract = {This paper describes two new live performance scenarios for performing music using bluetooth-enabled mobile phones. Interaction between mobile phones via wireless link is a key feature of the performance interface for each scenario. Both scenarios are discussed in the context of two publicly performed works for an ensemble of players in which mobile phone handsets are used both as sound sources and as hand-held controllers. In both works mobile phones are mounted in a specially devised pouch attached to a cord and physically swung to produce audio chorusing. During performance some players swing phones while others operate phones as hand-held controllers. Wireless connectivity enables interaction between flying and hand-held phones. Each work features different bluetooth implementations. In one a dedicated mobile phone acts as a server that interconnects multiple clients, while in the other point to point communication takes place between clients on an ad hoc basis. The paper summarises bluetooth tools designed for live performance realisation and concludes with a comparative evaluation of both scenarios for future implementation of performance by large ensembles of nonexpert players performing microtonal music using ubiquitous technology. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Java 2 Micro Edition; j2me; Pure Data; PD; Real-Time Media Performance; Just Intonation.  },
pages = {37--42},
}
@inproceedings{Schiesser2006,
author = {Schiesser, S\'{e}bastien and Traube, Caroline},
url = {http://www.nime.org/proceedings/2006/nime2006_308.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {On Making and Playing an Electronically-augmented Saxophone},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {saxophone, augmented instrument, live electronics, perfor- mance, gestural control },
pages = {308--313},
}
@inproceedings{Schoonderwaldt2006,
author = {Schoonderwaldt, Erwin and Rasamimanana, Nicolas and Bevilacqua, Fr\'{e}d\'{e}ric},
url = {http://www.nime.org/proceedings/2006/nime2006_200.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Combining Accelerometer and Video Camera: Reconstruction of Bow Velocity Profiles},
year = {2006},
abstract = {A cost-effective method was developed for the estimation of the bow velocity in violin playing, using an accelerometer on the bow in combination with point tracking using a standard video camera. The video data are used to detect the moments of bow direction changes. This information is used for piece-wise integration of the accelerometer signal, resulting in a drift-free reconstructed velocity signal with a high temporal resolution. The method was evaluated using a 3D motion capturing system, providing a reliable reference of the actual bow velocity. The method showed good results when the accelerometer and video stream are synchronized. Additional latency and jitter of the camera stream can importantly decrease the performance of the method, depending on the bow stroke type. },
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Bowing gestures, bowed string, violin, bow velocity,  accelerometer, video tracking.  },
pages = {200--203},
}
@inproceedings{Serafin2006,
author = {Serafin, Stefania and de G\"{o}tzen, Amalia and B\"{o}ttcher, Niels and Gelineck, Steven},
url = {http://www.nime.org/proceedings/2006/nime2006_240.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Synthesis and Control of Everyday Sounds Reconstructing Russolo’s Intonarumori},
year = {2006},
abstract = {In this paper we introduce the Croaker, a novel input deviceinspired by Russolo's Intonarumori. We describe the components of the controller and the sound synthesis engine whichallows to reproduce several everyday sounds.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Noise machines, everyday sounds, physical models. },
pages = {240--245},
}
@inproceedings{Smyth2006,
author = {Smyth, Tamara},
url = {http://www.nime.org/proceedings/2006/nime2006_314.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Handheld Acoustic Filter Bank for Musical Control},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {khaen, sound synthesis control, mapping, musical acoustics },
pages = {314--317},
}
@inproceedings{Steiner2006,
author = {Steiner, Hans-Christoph},
url = {http://www.nime.org/proceedings/2006/nime2006_106.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Towards a Catalog and Software Library of Mapping Methods},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
pages = {106--109},
}
@inproceedings{Stewart2006,
author = {Stewart, D. Andrew},
url = {http://www.nime.org/proceedings/2006/nime2006_103.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {SonicJumper Composer},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {composition, process, materials, gesture, controller, cross- modal interaction  },
pages = {103--105},
}
@inproceedings{Tanaka2006,
author = {Tanaka, Atau and Gemeinboeck, Petra},
url = {http://www.nime.org/proceedings/2006/nime2006_026.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Framework for Spatial Interaction in Locative Media},
year = {2006},
abstract = {This paper presents the concepts and techniques used in afamily of location based multimedia works. The paper hasthree main sections: 1.) to describe the architecture of anaudio-visual hardware/software framework we havedeveloped for the realization of a series of locative mediaartworks, 2.) to discuss the theoretical and conceptualunderpinnings motivating the design of the technicalframework, and 3.) to elicit from this, fundamental issuesand questions that can be generalized and applicable to thegrowing practice of locative media.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Mobile music, urban fiction, locative media. },
pages = {26--30},
}
@inproceedings{Wanderley2006,
author = {Wanderley, Marcelo M. and Birnbaum, David and Malloch, Joseph and Sinyor, Elliot and Boissinot, Julien},
url = {http://www.nime.org/proceedings/2006/nime2006_180.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {SensorWiki.org: A Collaborative Resource for Researchers and Interface Designers},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {sensors, Wiki, collaborative website, open content },
pages = {180--183},
}
@inproceedings{Wang2006,
author = {Wang, Ge and Misra, Ananya and Cook, Perry R.},
url = {http://www.nime.org/proceedings/2006/nime2006_049.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Building Collaborative Graphical interFaces in the Audicle},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Graphical interfaces, collaborative performance, networking,  computer music ensemble, emergence, visualization,  education.  },
pages = {49--52},
}
@inproceedings{Weinberg2006,
author = {Weinberg, Gil and Thatcher, Travis},
url = {http://www.nime.org/proceedings/2006/nime2006_246.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Interactive Sonification of Neural Activity},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {1,background and motivations,biological research,interactive auditory display,neural patterns,scholars are,sonification,with new developments in},
pages = {246--249},
}
@inproceedings{Wozniewski2006,
author = {Wozniewski, Mike and Settel, Zack and Cooperstock, Jeremy R.},
url = {http://www.nime.org/proceedings/2006/nime2006_144.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {A Framework for Immersive Spatial Audio Performance},
year = {2006},
abstract = {Traditional uses of virtual audio environments tend to focus onperceptually accurate acoustic representations. Though spatialization of sound sources is important, it is necessary to leveragecontrol of the sonic representation when considering musical applications. The proposed framework allows for the creation ofperceptually immersive scenes that function as musical instruments. Loudspeakers and microphones are modeled within thescene along with the listener/performer, creating a navigable 3Dsonic space where sound sources and sinks process audio according to user-defined spatial mappings.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Control paradigms, 3D audio, spatialization, immersive audio environments, auditory display, acoustic modeling, spatial inter- faces, virtual instrument design },
pages = {144--149},
}
@inproceedings{Young2006,
author = {Young, Diana and Nunn, Patrick and Vassiliev, Artem},
url = {http://www.nime.org/proceedings/2006/nime2006_396.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Composing for Hyperbow: A Collaboration Between MIT and the Royal Academy of Music},
year = {2006},
abstract = {In this paper we present progress of an ongoingcollaboration between researchers at the MIT MediaLaboratory and the Royal Academy of Music (RAM). The aimof this project is to further explore the expressive musicalpotential of the Hyperbow, a custom music controller firstdesigned for use in violin performance. Through the creationof new repertoire, we hope to stimulate the evolution of thisinterface, advancing its usability and refining itscapabilities. In preparation for this work, the Hyperbowsystem has been adapted for cello (acoustic and electric)performance. The structure of our collaboration is described,and two of the pieces currently in progress are presented.Feedback from the performers is also discussed, as well asfuture plans.},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Cello, bow, controller, electroacoustic music, composition. },
pages = {396--401},
}
@inproceedings{Zadel2006,
author = {Zadel, Mark and Scavone, Gary},
url = {http://www.nime.org/proceedings/2006/nime2006_168.pdf},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
title = {Different Strokes: a Prototype Software System for Laptop Performance and Improvisation},
year = {2006},
editor = {Schnell, Norbert and Bevilacqua, Fr\'{e}d\'{e}ric and Michael Lyons and Atau Tanaka},
address = {Paris, France},
keywords = {Software control of computer music, laptop performance, graphical interfaces, freehand input, dynamic simulation },
pages = {168--171},
}
