% This file was created with JabRef 2.10.
% Encoding: UTF-8


@InProceedings{Allison2003,
  Title                    = {SensorBox: Practical Audio Interface for Gestural Performance},
  Author                   = {Allison, Jesse T. and Place, Timothy},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {208--210},

  Abstract                 = {SensorBox is a low cost, low latency, high-resolutioninterface for obtaining gestural data from sensors for use inrealtime with a computer-based interactive system. Wediscuss its implementation, benefits, current limitations, andcompare it with several popular interfaces for gestural dataacquisition.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Sensors, gestural acquisition, audio interface, interactive music, SensorBox. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_208.pdf}
}

@InProceedings{Andersen2003,
  Title                    = {Mixxx : Towards Novel DJ Interfaces},
  Author                   = {Andersen, Tue H.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {30--35},

  Abstract                 = {The Disc Jockey (DJ) software system Mixxx is presented.Mixxx makes it possible to conduct studies of new interaction techniques in connection with the DJ situation, by itsopen design and easy integration of new software modulesand MIDI connection to external controllers. To gain a better understanding of working practices, and to aid the designprocess of new interfaces, interviews with two contemporarymusicians and DJ's are presented. In contact with thesemusicians development of several novel prototypes for DJinteraction have been made. Finally implementation detailsof Mixxx are described.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_030.pdf}
}

@InProceedings{Baalman2003,
  Title                    = {The STRIMIDILATOR: a String Controlled MIDI-Instrument},
  Author                   = {Baalman, Marije A.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {19--23},

  Abstract                 = {The STRIMIDILATOR is an instrument that uses the deviation and the vibration of strings as MIDI-controllers. Thismethod of control gives the user direct tactile force feedbackand allows for subtle control. The development of the instrument and its different functions are described.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {MIDI controllers, tactile force feedback, strings. Figure The STRIMIDILATOR },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_019.pdf}
}

@InProceedings{Baird2003,
  Title                    = {Multi-Conductor: An Onscreen Polymetrical Conducting and Notation Display System},
  Author                   = {Baird, Kevin C.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {211--212},

  Abstract                 = {This software tool, developed in Max/MSP, presentsperformers with image files consisting of traditional notationas well as conducting in the form of video playback. Theimpetus for this work was the desire to allow the musicalmaterial for each performer of a given piece to differ withregard to content and tempo.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Open form, notation, polymeter, polytempi, Max/MSP. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_211.pdf}
}

@InProceedings{Blaine2003,
  Title                    = {Contexts of Collaborative Musical Experiences},
  Author                   = {Blaine, Tina and Fels, Sidney S.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {129--134},

  Abstract                 = {We explore a variety of design criteria applicable to thecreation of collaborative interfaces for musical experience. Themain factor common to the design of most collaborativeinterfaces for novices is that musical control is highlyrestricted, which makes it possible to easily learn andparticipate in the collective experience. Balancing this tradeoff is a key concern for designers, as this happens at theexpense of providing an upward path to virtuosity with theinterface. We attempt to identify design considerationsexemplified by a sampling of recent collaborative devicesprimarily oriented toward novice interplay. It is our intentionto provide a non-technical overview of design issues inherentin configuring multiplayer experiences, particularly for entrylevel players.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Design, collaborative interface, musical experience, multiplayer, novice, musical control. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_129.pdf}
}

@InProceedings{Burtner2003,
  Title                    = {Composing for the (dis)Embodied Ensemble : Notational Systems in (dis)Appearances},
  Author                   = {Burtner, Matthew},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {63--69},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_063.pdf}
}

@InProceedings{Cadoz2003,
  Title                    = {{AC}ROE - {ICA} Artistic Creation and Computer Interactive Multisensory Simulation Force Feedback Gesture Transducers},
  Author                   = {Cadoz, Claude and Luciani, Annie and Florens, Jean-Loup and Castagn\'{e}, Nicolas},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {235--246},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_235.pdf}
}

@InProceedings{Cannon2003,
  Title                    = {EpipE: Exploration of the Uilleann Pipes as a Potential Controller for Computer-based Music},
  Author                   = {Cannon, Cormac and Hughes, Stephen and O'Modhrain, Sile},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {3--8},

  Abstract                 = {In this paper we present a design for the EpipE, a newexpressive electronic music controller based on the IrishUilleann Pipes, a 7-note polyphonic reeded woodwind. Thecore of this proposed controller design is a continuouselectronic tonehole-sensing arrangement, equally applicableto other woodwind interfaces like those of the flute, recorder orJapanese shakuhachi. The controller will initially be used todrive a physically-based synthesis model, with the eventualgoal being the development of a mapping layer allowing theEpipE interface to operate as a MIDI-like controller of arbitrarysynthesis models.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Controllers, continuous woodwind tonehole sensor, uilleann pipes, Irish bagpipe, physical modelling, double reed, conical bore, tonehole. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_003.pdf}
}

@InProceedings{Choi2003,
  Title                    = {A Component Model of Gestural Primitive Throughput},
  Author                   = {Choi, Insook},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {201--204},

  Abstract                 = {This paper suggests that there is a need for formalizing acomponent model of gestural primitive throughput in musicinstrument design. The purpose of this model is to construct acoherent and meaningful interaction between performer andinstrument. Such a model has been implicit in previous researchfor interactive performance systems. The model presented heredistinguishes gestural primitives from units of measure ofgestures. The throughput model identifies symmetry betweenperformance gestures and musical gestures, and indicates a rolefor gestural primitives when a performer navigates regions ofstable oscillations in a musical instrument. The use of a highdimensional interface tool is proposed for instrument design, forfine-tuning the mapping between movement sensor data andsound synthesis control data.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Performance gestures, musical gestures, instrument design, mapping, tuning, affordances, stability. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_201.pdf}
}

@InProceedings{Couturier2003,
  Title                    = {Pointing Fingers: Using Multiple Direct Interactions with Visual Objects to Perform Music},
  Author                   = {Couturier, Jean-Michel and Arfib, Daniel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {184--187},

  Abstract                 = {In this paper, we describe a new interface for musicalperformance, using the interaction with a graphical userinterface in a powerful manner: the user directly touches ascreen where graphical objects are displayed and can useseveral fingers simultaneously to interact with the objects. Theconcept of this interface is based on the superposition of thegesture spatial place and the visual feedback spatial place; i tgives the impression that the graphical objects are real. Thisconcept enables a huge freedom in designing interfaces. Thegesture device we have created gives the position of fourfingertips using 3D sensors and the data is performed in theMax/MSP environment. We have realized two practicalexamples of musical use of such a device, using PhotosonicSynthesis and Scanned Synthesis.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {HCI, touch screen, multimodality, mapping, direct interaction, gesture devices, bimanual interaction, two-handed, Max/MSP. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_184.pdf}
}

@InProceedings{Dobrian2003,
  Title                    = {Gestural Control of Music Using the Vicon 8 Motion Capture System},
  Author                   = {Dobrian, Christopher and Bevilacqua, Fr\'{e}d\'{e}ric},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {161--163},

  Date                     = {22-24 May, 2003},
  Keywords                 = {Motion capture, gestural control, mapping. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_161.pdf}
}

@InProceedings{Flety2003,
  Title                    = {EoBody : a Follow-up to AtoMIC Pro's Technology},
  Author                   = {Fl\'{e}ty, Emmanuel and Sirguy, Marc},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {225--226},

  Abstract                 = {Ircam has been deeply involved into gesture analysis and sensingfor about four years now, as several artistic projects demonstrate.Ircam has often been solicited for sharing software and hardwaretools for gesture sensing, especially devices for the acquisition andconversion of sensor data, such as the AtoMIC Pro [1][2]. Thisdemo-paper describes the recent design of a new sensor to MIDIinterface called EoBody1},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Gestural controller, Sensor, MIDI, Computer Music. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_225.pdf}
}

@InProceedings{Gaye2003,
  Title                    = {Sonic City: The Urban Environment as a Musical Interface},
  Author                   = {Gaye, Lalya and Maz\'{e}, Ramia and Holmquist, Lars E.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {109--115},

  Abstract                 = {In the project Sonic City, we have developed a system thatenables users to create electronic music in real time by walkingthrough and interacting with the urban environment. Weexplore the use of public space and everyday behaviours forcreative purposes, in particular the city as an interface andmobility as an interaction model for electronic music making.A multi-disciplinary design process resulted in theimplementation of a wearable, context-aware prototype. Thesystem produces music by retrieving information aboutcontext and user action and mapping it to real-time processingof urban sounds. Potentials, constraints, and implications ofthis type of music creation are discussed.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_109.pdf}
}

@InProceedings{Hatanaka2003,
  Title                    = {Ergonomic Design of A Portable Musical Instrument},
  Author                   = {Hatanaka, Motohide},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {77--82},

  Abstract                 = {A handheld electronic musical instrument, named the BentoBox, was developed. The motivation was to develop aninstrument which one can easily carry around and play inmoments of free time, for example when riding public transportation or during short breaks at work. The device wasdesigned to enable quick learning by having various scalesprogrammed for different styles of music, and also beexpressive by having hand controlled timbral effects whichcan be manipulated while playing. Design analysis anditeration lead to a compact and ergonomic device. This paperfocuses on the ergonomic design process of the hardware.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {MIDI controller, electronic musical instrument, musical instrument design, ergonomics, playability, human computer interface. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_077.pdf}
}

@InProceedings{Hewitt2003,
  Title                    = {E-mic: Extended Mic-stand Interface Controller},
  Author                   = {Hewitt, Donna and Stevenson, Ian},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {122--128},

  Date                     = {22-24 May, 2003},
  Keywords                 = {Alternate controller, gesture, microphone technique, vocal performance, performance interface, electronic music. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_122.pdf}
}

@InProceedings{Hoskinson2003,
  Title                    = {Real-time Adaptive Control of Modal Synthesis},
  Author                   = {Hoskinson, Reynald and van den Doel, Kees and Fels, Sidney S.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {99--103},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_099.pdf}
}

@InProceedings{Howard2003,
  Title                    = {Force Feedback Gesture Controlled Physical Modelling Synthesis},
  Author                   = {Howard, David M. and Rimell, Stuart and Hunt, Andy D.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {95--98},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_095.pdf}
}

@InProceedings{Hunt2003,
  Title                    = {MidiGrid: Past, Present and Future},
  Author                   = {Hunt, Andy D. and Kirk, Ross},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {135--139},

  Abstract                 = {MidiGrid is a computer-based musical instrument, primarilycontrolled with the computer mouse, which allows liveperformance of MIDI-based musical material by mapping 2dimensional position onto musical events. Since itsinvention in 1987, it has gained a small, but enthusiastic,band of users, and has become the primary instrument forseveral people with physical disabilities. This paper reviewsits development, uses and user interface issues, and highlightsthe work currently in progress for its transformation intoMediaGrid.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_135.pdf}
}

@InProceedings{Jorda2003,
  Title                    = {Sonigraphical Instruments: From {FM}OL to the reacTable*},
  Author                   = {Jord\`{a}, Sergi},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {70--76},

  Abstract                 = {This paper first introduces two previous software-based musicinstruments designed by the author, and analyses the crucialimportance of the visual feedback introduced by theirinterfaces. A quick taxonomy and analysis of the visualcomponents in current trends of interactive music software isthen proposed, before introducing the reacTable*, a newproject that is currently under development. The reacTable* isa collaborative music instrument, aimed both at novices andadvanced musicians, which employs computer vision andtangible interfaces technologies, and pushes further the visualfeedback interface ideas and techniques aforementioned.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_070.pdf}
}

@InProceedings{Kartadinata2003,
  Title                    = {The Gluiph: a Nucleus for Integrated Instruments},
  Author                   = {Kartadinata, Sukandar},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {180--183},

  Abstract                 = {In this paper I present the gluiph, a single-board computer thatwas conceived as a platform for integrated electronic musicalinstruments. It aims to provide new instruments as well asexisting ones with a stronger identity by untethering themfrom the often lab-like stage setups built around general purpose computers. The key additions to its core are a flexiblesensor subsystem and multi-channel audio I/O. In contrast toother stand-alone approaches it retains a higher degree offlexibility by supporting popular music programming languages, with Miller Puckette's pd [1] being the current focus.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_180.pdf}
}

@InProceedings{Kessous2003,
  Title                    = {Bimanuality in Alternate Musical Instruments},
  Author                   = {Kessous, Lo\"{\i}c and Arfib, Daniel},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {140--145},

  Abstract                 = {This paper presents a study of bimanual control applied tosound synthesis. This study deals with coordination,cooperation, and abilities of our hands in musical context. Wedescribe examples of instruments made using subtractivesynthesis, scanned synthesis in Max/MSP and commercialstand-alone software synthesizers via MIDI communicationprotocol. These instruments have been designed according to amulti-layer-mapping model, which provides modular design.They have been used in concerts and performanceconsiderations are discussed too.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Gesture control, mapping, alternate controllers, musical instruments. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_140.pdf}
}

@InProceedings{Kleinsasser2003,
  Title                    = {Dsp.rack: Laptop-based Modular, Programmable Digital Signal Processing and Mixing for Live Performance},
  Author                   = {Kleinsasser, William},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {213--215},

  Abstract                 = {This document describes modular software supporting livesignal processing and sound file playback within theMax/MSP environment. Dsp.rack integrates signalprocessing, memory buffer recording, and pre-recordedmulti-channel file playback using an interconnected,programmable signal flow matrix, and an eight-channel i/oformat.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Digital signal processing, Max/MSP, computer music performance, matrix routing, live performance processing. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_213.pdf}
}

@InProceedings{Laibowitz2003,
  Title                    = {BASIS: A Genesis in Musical Interfaces},
  Author                   = {Laibowitz, Mat},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {216--217},

  Abstract                 = {This paper is a demo proposal for a new musical interfacebased on a DNA-like double-helix and concepts in charactergeneration. It contains a description of the interface,motivations behind developing such an interface, variousmappings of the interface to musical applications, and therequirements to demo the interface.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Performance, Design, Experimentation, DNA, Big Five. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_216.pdf}
}

@InProceedings{Lyons2003,
  Title                    = {Designing, Playing, and Performing with a Vision-based Mouth Interface},
  Author                   = {Lyons, Michael J. and Haehnel, Michael and Tetsutani, Nobuji},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {116--121},

  Abstract                 = {The role of the face and mouth in speech production as well asnon-verbal communication suggests the use of facial action tocontrol musical sound. Here we document work on theMouthesizer, a system which uses a headworn miniaturecamera and computer vision algorithm to extract shapeparameters from the mouth opening and output these as MIDIcontrol changes. We report our experience with variousgesture-to-sound mappings and musical applications, anddescribe a live performance which used the Mouthesizerinterface.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Video-based interface; mouth controller; alternative input devices. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_116.pdf}
}

@InProceedings{Merrill2003,
  Title                    = {Head-Tracking for Gestural and Continuous Control of Parameterized Audio Effects},
  Author                   = {Merrill, David},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {218--219},

  Abstract                 = {This paper describes a system which uses the output fromhead-tracking and gesture recognition software to drive aparameterized guitar effects synthesizer in real-time.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Head-tracking, gestural control, continuous control, parameterized effects processor. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_218.pdf}
}

@InProceedings{Modler2003,
  Title                    = {An Experimental Set of Hand Gestures for Expressive Control of Musical Parameters in Realtime},
  Author                   = {Modler, Paul and Myatt, Tony and Saup, Michael},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {146--150},

  Abstract                 = {This paper describes the implementation of Time Delay NeuralNetworks (TDNN) to recognize gestures from video images.Video sources are used because they are non-invasive and do notinhibit performer's physical movement or require specialistdevices to be attached to the performer which experience hasshown to be a significant problem that impacts musiciansperformance and can focus musical rehearsals and performancesupon technical rather than musical concerns (Myatt 2003).We describe a set of hand gestures learned by an artificial neuralnetwork to control musical parameters expressively in real time.The set is made up of different types of gestures in order toinvestigate:-aspects of the recognition process-expressive musical control-schemes of parameter mapping-generalization issues for an extended set for musicalcontrolThe learning procedure of the Neural Network is describedwhich is based on variations by affine transformations of imagesequences of the hand gestures.The whole application including the gesture capturing isimplemented in jMax to achieve real time conditions and easyintegration into a musical environment to realize differentmappings and routings of the control stream.The system represents a practice-based research using actualmusic models like compositions and processes of compositionwhich will follow the work described in the paper.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Gesture Recognition, Artificial Neural Network, Expressive Control, Real-time Interaction },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_146.pdf}
}

@InProceedings{Momeni2003,
  Title                    = {Characterizing and Controlling Musical Material Intuitively with Geometric Models},
  Author                   = {Momeni, Ali and Wessel, David},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {54--62},

  Abstract                 = {In this paper, we examine the use of spatial layouts of musicalmaterial for live performance control. Emphasis is given tosoftware tools that provide for the simple and intuitivegeometric organization of sound material, sound processingparameters, and higher-level musical structures.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_054.pdf}
}

@InProceedings{Muth2003,
  Title                    = {Sodaconductor},
  Author                   = {Muth, David and Burton, Ed},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {222--224},

  Abstract                 = {Sodaconductor is a musical interface for generating OSCcontrol data based on the dynamic physical simulation toolSodaconstructor as it can be seen and heard onhttp://www.sodaplay.com.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_222.pdf}
}

@InProceedings{Nagashima2003,
  Title                    = {Bio-Sensing Systems and Bio-Feedback Systems for Interactive Media Arts},
  Author                   = {Nagashima, Yoichi},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {48--53},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_048.pdf}
}

@InProceedings{Nakra2003,
  Title                    = {Immersion Music: a Progress Report},
  Author                   = {Nakra, Teresa M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {151--152},

  Abstract                 = {This paper describes the artistic projects undertaken at ImmersionMusic, Inc. (www.immersionmusic.org) during its three-yearexistence. We detail work in interactive performance systems,computer-based training systems, and concert production.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Interactive computer music systems, gestural interaction, Conductor's Jacket, Digital Baton },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_151.pdf}
}

@InProceedings{Newton-Dunn2003,
  Title                    = {Block Jam: A Tangible Interface for Interactive Music},
  Author                   = {Newton-Dunn, Henry and Nakano, Hiroaki and Gibson, James},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {170--177},

  Abstract                 = {In this paper, we introduce Block Jam, a Tangible UserInterface that controls a dynamic polyrhythmic sequencerusing 26 physical artifacts. These physical artifacts, that wecall blocks, are a new type of input device for manipulatingan interactive music system. The blocks' functional andtopological statuses are tightly coupled to an ad hocsequencer, interpreting the user's arrangement of the blocksas meaningful musical phrases and structures.We demonstrate that we have created both a tangible andvisual language that enables both the novice and musicallytrained users by taking advantage of both their explorativeand intuitive abilities. The tangible nature of the blocks andthe intuitive interface promotes face-to-face collaborationand social interaction within a single system. The principleof collaboration is further extended by linking two BlockJam systems together to create a network.We discuss our project vision, design rational, relatedworks, and the implementation of Block Jam prototypes.Figure 1. A cluster of blocks, note the mother block on thebottom right},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Tangible interface, modular system, polyrhythmic sequencer. VISION We believe in a future where music will no longer be considered a linear composition, but a dynamic structure, and musical composition will extend to interaction. We also believe that through the },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_170.pdf}
}

@InProceedings{Nishimoto2003,
  Title                    = {Why Always Versatile? Dynamically Customizable Musical Instruments Facilitate Expressive Performances},
  Author                   = {Nishimoto, Kazushi and Oshima, Chika and Miyagawa, Yohei},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {164--169},

  Abstract                 = {In this paper, we discuss a design principle for the musicalinstruments that are useful for both novices and professionalmusicians and that facilitate musically rich expression. Webelieve that the versatility of conventional musicalinstruments causes difficulty in performance. By dynamicallyspecializing a musical instrument for performing a specific(genre of) piece, the musical instrument could become moreuseful for performing the piece and facilitates expressiveperformance. Based on this idea, we developed two new typesof musical instruments, i.e., a "given-melody-based musicalinstrument" and a "harmonic-function-based musicalinstrument." From the experimental results using twoprototypes, we demonstrate the efficiency of the designprinciple.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_164.pdf}
}

@InProceedings{Orio2003,
  Title                    = {Score Following: State of the Art and New Developments},
  Author                   = {Orio, Nicola and Lemouton, Serge and Schwarz, Diemo},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {36--41},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_036.pdf}
}

@InProceedings{PalacioQuintin2003,
  Title                    = {The Hyper-Flute},
  Author                   = {Palacio-Quintin, Cl\'{e}o},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {206--207},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_206.pdf}
}

@InProceedings{Paradiso2003,
  Title                    = {Dual-Use Technologies for Electronic Music Controllers: A Personal Perspective},
  Author                   = {Paradiso, Joseph A.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {228--234},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_228.pdf}
}

@InProceedings{Peiper2003,
  Title                    = {An Interface for Real-time Classification of Articulations Produced by Violin Bowing},
  Author                   = {Peiper, Chad and Warden, David and Garnett, Guy},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {192--196},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_192.pdf}
}

@InProceedings{Ryan2003,
  Title                    = {TGarden: Wearable Instruments and Augmented Physicality},
  Author                   = {Ryan, Joel and Salter, Christopher L.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {87--90},

  Abstract                 = {This report details work on the interdisciplinary mediaproject TGarden. The authors discuss the challengesencountered while developing a responsive musicalenvironment for the general public involving wearable,sensor-integrated clothing as the central interface and input device. The project's dramaturgical andtechnical/implementation background are detailed toprovide a framework for the creation of a responsive hardwareand software system that reinforces a tangible relationshipbetween the participant's improvised movement and musicalresponse. Finally, the authors take into consideration testingscenarios gathered from public prototypes in two Europeanlocales in 2001 to evaluate user experience of the system.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Gesture, interaction, embodied action, enaction, physical model, responsive environment, interactive musical systems, affordance, interface, phenomenology, energy, kinetics, time constant, induced ballistics, wearable computing, accelerometer, audience participation, dynamical system, dynamic compliance, effort, wearable instrument, augmented physicality. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_087.pdf}
}

@InProceedings{Scavone2003,
  Title                    = {THE PIPE: Explorations with Breath Control},
  Author                   = {Scavone, Gary},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {15--18},

  Date                     = {22-24 May, 2003},
  Keywords                 = {MIDI Controller, Wind Controller, Breath Control, Human Computer Interaction. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_015.pdf}
}

@InProceedings{Settel2003,
  Title                    = {Convolution Brother's Instrument Design},
  Author                   = {Settel, Zack and Lippe, Cort},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {197--200},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_197.pdf}
}

@InProceedings{Shiraiwa2003,
  Title                    = {Sound Kitchen: Designing a Chemically Controlled Musical Performance},
  Author                   = {Shiraiwa, Hiroko and Segnini, Rodrigo and Woo, Vivian},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {83--86},

  Date                     = {22-24 May, 2003},
  Keywords                 = {Chemical music, Applied chemistry, Battery Controller. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_083.pdf}
}

@InProceedings{Singer2003,
  Title                    = {Sonic Banana: A Novel Bend-Sensor-Based MIDI Controller},
  Author                   = {Singer, Eric},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {220--221},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_220.pdf}
}

@InProceedings{Singer2003a,
  Title                    = {LEMUR GuitarBot: MIDI Robotic String Instrument},
  Author                   = {Singer, Eric and Larke, Kevin and Bianciardi, David},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {188--191},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_188.pdf}
}

@InProceedings{Traube2003,
  Title                    = {Indirect Acquisition of Instrumental Gesture Based on Signal , Physical and Perceptual Information},
  Author                   = {Traube, Caroline and Depalle, Philippe and Wanderley, Marcelo M.},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {42--47},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_042.pdf}
}

@InProceedings{Ventura2003,
  Title                    = {Duet Musical Companion: Improvisational Interfaces for Children},
  Author                   = {Ventura, David and Mase, Kenji},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {91--94},

  Abstract                 = {We present a sensor-doll interface as a musical outlet forpersonal expression. A doll serves the dual role of being bothan expressive agent and a playmate by allowing solo andaccompanied performance. An internal computer and sensorsystem allow the doll to receive input from the user and itssurroundings, and then respond accordingly with musicalfeedback. Sets of musical timbres and melodies may bechanged by presenting the doll with a series of themed clothhats, each suggesting a different style of play. The doll mayperform by itself and play a number of melodies, or it maycollaborate with the user when its limbs are squeezed or bent.Shared play is further encouraged by a basic set of aural tonesmimicking conversation.},
  Date                     = {22-24 May, 2003},
  Keywords                 = {Musical improvisation, toy interface agent, sensor doll, context awareness. },
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_091.pdf}
}

@InProceedings{Wilson2003,
  Title                    = {Microcontrollers in Music HCI Instruction: Reflections on our Switch to the Atmel AVR Platform},
  Author                   = {Wilson, Scott and Gurevich, Michael and Verplank, Bill and Stang, Pascal},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {24--29},

  Abstract                 = {Over the past year the instructors of the Human ComputerInteraction courses at CCRMA have undertaken a technology shift to a much more powerful teaching platform. Wedescribe the technical features of the new Atmel AVR basedplatform, contrasting it with the Parallax BASIC Stampplatform used in the past. The successes and failures ofthe new platform are considered, and some student projectsuccess stories described.},
  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_024.pdf}
}

@InProceedings{Wright2003,
  Title                    = {OpenSound Control: State of the Art 2003},
  Author                   = {Wright, Matthew and Freed, Adrian and Momeni, Ali},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {153--159},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_153.pdf}
}

@InProceedings{Young2003,
  Title                    = {HyperPuja: A Tibetan Singing Bowl Controller},
  Author                   = {Young, Diana and Essl, Georg},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {9--14},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_009.pdf}
}

@InProceedings{Young2003a,
  Title                    = {Playability Evaluation of a Virtual Bowed String Instrument},
  Author                   = {Young, Diana and Serafin, Stefania},
  Booktitle                = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  Year                     = {2003},

  Address                  = {Montreal, Canada},
  Pages                    = {104--108},

  Date                     = {22-24 May, 2003},
  Url                      = {http://www.nime.org/proceedings/2003/nime2003_104.pdf}
}
